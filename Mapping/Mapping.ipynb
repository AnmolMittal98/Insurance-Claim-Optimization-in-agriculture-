{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://deepsense.ai/satellite-images-semantic-segmentation-with-deep-learning/\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convolution Neural Network\n",
    "class ConvRelu(torch.nn.Module):\n",
    "    def __init__(self, in_depth, out_depth):\n",
    "      super(ConvRelu, self).__init__()\n",
    "      self.conv = torch.nn.Conv2d(in_depth, out_depth, kernel_size=3, stride=1, padding=1)\n",
    "      self.activation = torch.nn.ReLU(inplace=True)\n",
    "    def forward(self, x):\n",
    "      x = self.conv(x)\n",
    "      x = self.activation(x)\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decode Block - Upsizing tensor to generate images from Neural Network\n",
    "class DecoderBlock(torch.nn.Module):\n",
    "    def __init__(self, in_depth, middle_depth, out_depth):\n",
    "      super(DecoderBlock, self).__init__()\n",
    "      self.conv_relu = ConvRelu(in_depth, middle_depth)\n",
    "      self.conv_transpose = torch.nn.ConvTranspose2d(middle_depth, out_depth, kernel_size=4, stride=2, padding=1)\n",
    "      self.activation = torch.nn.ReLU(inplace=True)\n",
    "    def forward(self, x):\n",
    "      x = self.conv_relu(x)\n",
    "      x = self.conv_transpose(x)\n",
    "      x = self.activation(x)\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UNetArchitechture\n",
    "class UNetResNet(torch.nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "      super(UNetResNet, self).__init__()\n",
    "      \n",
    "      self.encoder = torchvision.models.resnet101(pretrained=True)\n",
    "      \n",
    "      self.pool = torch.nn.MaxPool2d(2, 2)\n",
    "      self.conv1 = torch.nn.Sequential(self.encoder.conv1, self.encoder.bn1, self.encoder.relu, self.pool)\n",
    "      self.conv2 = self.encoder.layer1\n",
    "      self.conv3 = self.encoder.layer2\n",
    "      self.conv4 = self.encoder.layer3\n",
    "      self.conv5 = self.encoder.layer4\n",
    "      \n",
    "      self.pool = torch.nn.MaxPool2d(2, 2)      \n",
    "      self.center = DecoderBlock(2048, 512, 256)\n",
    "      \n",
    "      self.dec5 = DecoderBlock(2048 + 256, 512, 256)\n",
    "      self.dec4 = DecoderBlock(1024 + 256, 512, 256)\n",
    "      self.dec3 = DecoderBlock(512 + 256, 256, 64)\n",
    "      self.dec2 = DecoderBlock(256 + 64, 128, 128)\n",
    "      self.dec1 = DecoderBlock(128, 128, 32)\n",
    "      self.dec0 = ConvRelu(32, 32)\n",
    "      self.final = torch.nn.Conv2d(32, num_classes, kernel_size=1)\n",
    "    def forward(self, x):\n",
    "      conv1 = self.conv1(x)\n",
    "      conv2 = self.conv2(conv1)\n",
    "      conv3 = self.conv3(conv2)\n",
    "      conv4 = self.conv4(conv3)\n",
    "      conv5 = self.conv5(conv4)\n",
    "      pool = self.pool(conv5)\n",
    "      center = self.center(pool)\n",
    "      dec5 = self.dec5(torch.cat([center, conv5], 1))\n",
    "      dec4 = self.dec4(torch.cat([dec5, conv4], 1))\n",
    "      dec3 = self.dec3(torch.cat([dec4, conv3], 1))\n",
    "      dec2 = self.dec2(torch.cat([dec3, conv2], 1))\n",
    "      dec1 = self.dec1(dec2)\n",
    "      dec0 = self.dec0(dec1)\n",
    "      return self.final(dec0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-a193b9d90c7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mloss_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "unet_resnet = UNetResNet(num_classes=2)\n",
    "unet_resnet.train()\n",
    "cross_entropy_loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(unet_resnet.parameters(), lr=0.0001, weight_decay=0.0001)\n",
    "\n",
    "for epoch_idx in range(2):\n",
    "    loss_batches = []\n",
    "    for batch_idx, data in enumerate(train_dataloader):\n",
    "      imgs, masks = data\n",
    "      imgs = torch.autograd.Variable(imgs)\n",
    "      masks = torch.autograd.Variable(masks)\n",
    "      y = unet_resnet(imgs)\n",
    "      loss = cross_entropy_loss(y, masks)\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      loss_batches.append(loss.data.cpu().numpy())\n",
    "    print('epoch: ',str(epoch_idx),' training loss: ',str(np.sum(loss_batches)))\n",
    "\n",
    "#Saving Model\n",
    "model_file = './unet-' + str(epoch_idx)\n",
    "unet_resnet = unet_resnet.cpu()\n",
    "torch.save(unet_resnet.state_dict(), model_file)\n",
    "unet_resnet = unet_resnet.cuda()\n",
    "print('model saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction\n",
    "unet_resnet = UNetResNet(num_classes=2)\n",
    "model_path= './unet-99'\n",
    "pretrained_model = torch.load(model_path)\n",
    "for name, tensor in pretrained_model.items():\n",
    "    unet_resnet.state_dict()[name].copy_(tensor)\n",
    "unet_resnet.eval()\n",
    "softmax2d = torch.nn.Softmax2d()\n",
    "img = cv2.imread('./img.png')\n",
    "assert img.shape[0] % 64 == 0 and img.shape[1] % 64 == 0\n",
    "img = np.expand_dims(img, axis=0)\n",
    "img = (img / 255.0 - MEAN) / STD\n",
    "img = img.transpose(0, 3, 1, 2)\n",
    "img = torch.FloatTensor(img)\n",
    "img = img.cuda()\n",
    "with torch.no_grad():\n",
    "    pred = unet_resnet(img)\n",
    "    pred = softmax2d(pred)\n",
    "    pred = pred[0, 1, :, :] > 0.7\n",
    "pred = pred.data.cpu().numpy()\n",
    "mask = (pred * 255.0).astype(np.uint8)\n",
    "cv2.imwrite('./mask.png', mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
